{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles: From Decision Trees to Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, ExtraTreesRegressor\n",
    "\n",
    "cars = pd.read_csv('data/cars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>cubicinches</th>\n",
       "      <th>hp</th>\n",
       "      <th>weightlbs</th>\n",
       "      <th>time-to-60</th>\n",
       "      <th>year</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>305</td>\n",
       "      <td>130</td>\n",
       "      <td>3840</td>\n",
       "      <td>15</td>\n",
       "      <td>1980</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>36.1</td>\n",
       "      <td>4</td>\n",
       "      <td>91</td>\n",
       "      <td>60</td>\n",
       "      <td>1800</td>\n",
       "      <td>16</td>\n",
       "      <td>1979</td>\n",
       "      <td>Japan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>232</td>\n",
       "      <td>112</td>\n",
       "      <td>2835</td>\n",
       "      <td>15</td>\n",
       "      <td>1983</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>232</td>\n",
       "      <td>100</td>\n",
       "      <td>3288</td>\n",
       "      <td>16</td>\n",
       "      <td>1972</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>250</td>\n",
       "      <td>105</td>\n",
       "      <td>3353</td>\n",
       "      <td>15</td>\n",
       "      <td>1977</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg   cylinders  cubicinches   hp  weightlbs   time-to-60   year  \\\n",
       "256  17.0           8          305  130       3840           15   1980   \n",
       "257  36.1           4           91   60       1800           16   1979   \n",
       "258  22.0           6          232  112       2835           15   1983   \n",
       "259  18.0           6          232  100       3288           16   1972   \n",
       "260  22.0           6          250  105       3353           15   1977   \n",
       "\n",
       "       brand  \n",
       "256      US.  \n",
       "257   Japan.  \n",
       "258      US.  \n",
       "259      US.  \n",
       "260      US.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             float64\n",
       " cylinders        int64\n",
       " cubicinches     object\n",
       " hp               int64\n",
       " weightlbs       object\n",
       " time-to-60       int64\n",
       " year             int64\n",
       " brand           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the datatypes of these columns.\n",
    "\n",
    "cars.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             0\n",
       " cylinders      0\n",
       " cubicinches    0\n",
       " hp             0\n",
       " weightlbs      0\n",
       " time-to-60     0\n",
       " year           0\n",
       " brand          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look for nulls.\n",
    "\n",
    "cars.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d48c10a2ed97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Great! Let's map the cubicinches values to floats.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m' cubicinches'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   3823\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3824\u001b[0m         \"\"\"\n\u001b[0;32m-> 3825\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3826\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;31m# mapper is a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: "
     ]
    }
   ],
   "source": [
    "# Great! Let's map the cubicinches values to floats.\n",
    "\n",
    "cars[' cubicinches'].map(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['350', '89', '302', '400', '98', '351', '440', '183', '108', '97',\n",
       "       '225', '85', '304', '113', '107', '86', '121', '200', '91', '71',\n",
       "       '250', '120', '199', '231', '80', '232', ' ', '455', '318', '122',\n",
       "       '141', '340', '116', '156', '90', '360', '168', '305', '198',\n",
       "       '112', '119', '262', '134', '429', '115', '72', '105', '151', '88',\n",
       "       '307', '101', '79', '140', '114', '173', '144', '81', '267', '70',\n",
       "       '163', '171', '260', '131', '68', '96', '135', '390', '146', '258',\n",
       "       '83', '76', '383', '130', '110', '454'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars[' cubicinches'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>cubicinches</th>\n",
       "      <th>hp</th>\n",
       "      <th>weightlbs</th>\n",
       "      <th>time-to-60</th>\n",
       "      <th>year</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>105</td>\n",
       "      <td>3897</td>\n",
       "      <td>19</td>\n",
       "      <td>1976</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>19.8</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>85</td>\n",
       "      <td>2990</td>\n",
       "      <td>18</td>\n",
       "      <td>1980</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg   cylinders  cubicinches   hp  weightlbs   time-to-60   year  brand\n",
       "40   16.0           6               105       3897           19   1976    US.\n",
       "180  19.8           6                85       2990           18   1980    US."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What happened?\n",
    "cars[cars[' cubicinches'] == ' ']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the problem!\n",
    "cars[' cubicinches'] = cars[' cubicinches'].replace(' ', np.nan)\n",
    "cars[' cubicinches'] = cars[' cubicinches'].map(float)\n",
    "cars[' cubicinches'] = cars[' cubicinches'].replace(np.nan, cars[' cubicinches'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg                  16\n",
       " cylinders            6\n",
       " cubicinches    200.919\n",
       " hp                 105\n",
       " weightlbs         3897\n",
       " time-to-60          19\n",
       " year              1976\n",
       " brand              US.\n",
       "Name: 40, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.iloc[40, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>cubicinches</th>\n",
       "      <th>hp</th>\n",
       "      <th>weightlbs</th>\n",
       "      <th>time-to-60</th>\n",
       "      <th>year</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>19.1</td>\n",
       "      <td>6</td>\n",
       "      <td>225.0</td>\n",
       "      <td>90</td>\n",
       "      <td></td>\n",
       "      <td>19</td>\n",
       "      <td>1981</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>199.0</td>\n",
       "      <td>90</td>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>1971</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4</td>\n",
       "      <td>68.0</td>\n",
       "      <td>49</td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "      <td>1974</td>\n",
       "      <td>Europe.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg   cylinders   cubicinches   hp  weightlbs   time-to-60   year  \\\n",
       "14   19.1           6         225.0   90                      19   1981   \n",
       "33   21.0           6         199.0   90                      15   1971   \n",
       "172  29.0           4          68.0   49                      20   1974   \n",
       "\n",
       "        brand  \n",
       "14        US.  \n",
       "33        US.  \n",
       "172   Europe.  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What about the weight column?\n",
    "\n",
    "cars[cars[' weightlbs'] == ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars[' weightlbs'] = cars[' weightlbs'].replace(' ', np.nan)\n",
    "cars[' weightlbs'] = cars[' weightlbs'].map(float)\n",
    "cars[' weightlbs'] = cars[' weightlbs'].replace(np.nan, cars[' weightlbs'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             1.000000\n",
       " cylinders     -0.776710\n",
       " cubicinches   -0.802379\n",
       " hp            -0.774905\n",
       " weightlbs     -0.823800\n",
       " time-to-60     0.509070\n",
       " year           0.550441\n",
       "Name: mpg, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the correlations of the other features with MPG.\n",
    "\n",
    "cars.corr()['mpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=1, splitter='best')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cars.drop(['mpg', ' brand'], axis=1)\n",
    "y = cars['mpg']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   random_state=1)\n",
    "\n",
    "rt = DecisionTreeRegressor(random_state=1)\n",
    "rt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6694270665919115"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.27143572e-04, 3.41305010e-02, 9.04980010e-02, 7.10990784e-01,\n",
       "       1.14518375e-02, 1.52401732e-01])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single decision tree will often overfit your training data. There are steps one can take to help with this, like limiting the \"depth\" of the nodes. But it's often better to do something else: Plant another tree!\n",
    "\n",
    "Of course, if a second tree is going to be of any value, it has to be *different from* the first. Here's a good algorithm for achieving that:\n",
    "\n",
    "## Fitting a Set of Bagged Decision Trees\n",
    "\n",
    "### Bagging Algorithm\n",
    "\n",
    "Take a sample of your X_train and fit a decision tree to it. <br/>\n",
    "Replace the first batch of data and repeat. <br/>\n",
    "When you've got as many trees as you like, make use of all your individual trees' predictions to come up with some holistic prediction. (Most obviously, we could take the average of our predictions, but there are other methods we might try.)\n",
    "\n",
    "<br/>\n",
    "\n",
    "Because we're resampling our data with replacement, we're *bootstrapping*. <br/>\n",
    "Because we're making use of our many samples' predictions, we're *aggregating*. <br/>\n",
    "Because we're bootstrapping and aggregating all in the same algorithm, we're *bagging*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a bagging regressor\n",
    "\n",
    "bag = BaggingRegressor(n_estimators = 100, max_samples = 20, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
       "                 max_features=1.0, max_samples=20, n_estimators=100,\n",
       "                 n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
       "                 warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit it.\n",
    "\n",
    "bag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8201564187671238"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score it.\n",
    "\n",
    "bag.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a significant improvement in $R^2$! Let's see if we can do even better.\n",
    "\n",
    "## Fitting a Random Forest\n",
    "\n",
    "### Random Forest Algorithm\n",
    "\n",
    "Let's add an extra layer of randomization: Instead of using *all* the features of my model to optimize a branch at each node, I'll just choose a subset of my features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                      n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try a forest with 100 trees.\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 100, random_state = 1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9778174426913423"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score it.\n",
    "rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8268243466142511"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a Stand of Extremely Randomized Trees\n",
    "\n",
    "### Extra Trees Algorithm\n",
    "\n",
    "Sometimes we might want even one more bit of randomization. Instead of always choosing the *optimal* branching path, we might just choose a branching path at random. If we're doing that, then we've got extremely randomized trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                    max_features='auto', max_leaf_nodes=None,\n",
       "                    min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                    min_samples_leaf=1, min_samples_split=2,\n",
       "                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "                    oob_score=False, random_state=1, verbose=0,\n",
       "                    warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again let's try 100 trees. We'll also set `bootstrap=True`.\n",
    "\n",
    "et = ExtraTreesRegressor(n_estimators = 100, bootstrap = True, random_state = 1)\n",
    "et.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8667700164806271"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scoring\n",
    "\n",
    "et.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34006039, 0.17292651, 0.12332799, 0.19006072, 0.02729154,\n",
       "       0.14633287])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the feature importances (average of feature importances over all trees)\n",
    "\n",
    "et.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearching\n",
    "\n",
    "One method of hyperparameter tuning is **gridsearching**. The idea is to build mulitple models with different hyperparameter values and then see which one performs the best. The hyperparameters and the values to try form a sort of *grid* along which we are looking for the best performance.\n",
    "\n",
    "Scikit-Learn has a `GridSearchCV` class whose `fit()` method runs this procedure. Note that this can be quite computationally expensive since:\n",
    "\n",
    "- A model is constructed for each combination of hyperparameter values that we input; and\n",
    "- Each model is cross-validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define param grid.\n",
    "\n",
    "param_grid = {\n",
    "    'max_features': ['sqrt', 'log2', 0.1],\n",
    "    'criterion': ['mse', 'mae']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question: How many models will we be constructing with this grid?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the gridsearch object with five-fold cross-validation.\n",
    "\n",
    "gs = GridSearchCV(estimator=et, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=ExtraTreesRegressor(bootstrap=True, criterion='mse',\n",
       "                                           max_depth=None, max_features='auto',\n",
       "                                           max_leaf_nodes=None,\n",
       "                                           min_impurity_decrease=0.0,\n",
       "                                           min_impurity_split=None,\n",
       "                                           min_samples_leaf=1,\n",
       "                                           min_samples_split=2,\n",
       "                                           min_weight_fraction_leaf=0.0,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           oob_score=False, random_state=1,\n",
       "                                           verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'criterion': ['mse', 'mae'],\n",
       "                         'max_features': ['sqrt', 'log2', 0.1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit it.\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8588199479092135"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score it.\n",
    "\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mae', 'max_features': 'sqrt'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best parameter values!\n",
    "\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8514252297100134"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And the best score\n",
    "\n",
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
       "                    max_features='sqrt', max_leaf_nodes=None,\n",
       "                    min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                    min_samples_leaf=1, min_samples_split=2,\n",
       "                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "                    oob_score=False, random_state=1, verbose=0,\n",
       "                    warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And the best estimator\n",
    "\n",
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Model that Takes Raw Data as Input\n",
    "\n",
    "Suppose we go with the best estimator according to our gridsearch results. If we want our model to be able to make predictions of MPG for an uncleaned row of input, we'll need to be able to clean the row before modeling.\n",
    "\n",
    "The main cleaning moves that we made above were to fix the problems in the cubicinches and the weightlbs columns. We'll also need to drop the columns that don't belong in the model.\n",
    "\n",
    "Let's write functions that will take care of those problems.\n",
    "\n",
    "Suppose we've got our best-performing model already available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_best = ExtraTreesRegressor(n_estimators=100, bootstrap=True, random_state=1,\n",
    "                             max_features='sqrt', criterion='mae').fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(row):\n",
    "    import pandas as pd\n",
    "    series = pd.Series(row)\n",
    "    for col in [' cubicinches', ' weightlbs']:\n",
    "        series[col] = float(series[col])\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop(row):\n",
    "    return row.drop([' brand', 'mpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(row):\n",
    "    row_clean = clean(row)\n",
    "    row_preds = drop(row_clean)\n",
    "    return et_best.predict(row_preds.values.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'mpg': 25.0, ' cylinders': 6, ' cubicinches': '202', ' hp': 120,\n",
    "          ' weightlbs': '2300', ' time-to-60': 13, ' year': 2019, ' brand': 'China.'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25.526])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predict(new_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Use a Random Forest Classifier to predict the category of price range for the phones in this dataset. Try tuning some hyperparameters using GridSearch, and then write up a short paragraph about your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones_train = pd.read_csv('data/train.csv')\n",
    "\n",
    "phones_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
